# -*- coding: utf-8 -*-
"""retinanet in pytorch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ISB5JvDaYY-yG-_lF2rRqlFmf4F3xgId
"""

import torch
import torchvision
from torchvision import models
from torchvision import transforms as T
from PIL import Image
import matplotlib.pyplot as plt

#load
model = models.detection.retinanet_resnet50_fpn(pretrained=True)

tf_ = T.ToTensor() # transformer

img = Image.open("/content/image (3).png")
transformed = tf_(img)
batched = transformed.unsqueeze(0) # model input
int_img = torch.tensor(transformed * 255, dtype=torch.uint8)

img

model = model.eval()
with torch.no_grad():
  out = model(batched)

from torchvision.utils import draw_bounding_boxes

score_threshold = .7

first_out = out[0]

bounding_boxes_img = draw_bounding_boxes(int_img, first_out['boxes'][first_out['scores'] > score_threshold], width=8)

plt.imshow(bounding_boxes_img.permute(1, 2, 0)) # convert image to matplotlib compatible

import cv2
import torch
from torchvision.utils import draw_bounding_boxes

score_threshold = 0.7

model = model.eval()

video = cv2.VideoCapture('/content/Retail.mp4')

if not video.isOpened():
    print("Error: Could not open video.")
else:
    frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = video.get(cv2.CAP_PROP_FPS)

    output_video = cv2.VideoWriter(
        '/content/processed_output.mp4',
        cv2.VideoWriter_fourcc(*'mp4v'),
        fps,
        (frame_width, frame_height)
    )

    while video.isOpened():
        ret, frame = video.read()
        if not ret:
            break


        transformed = tf_(frame)
        batched = transformed.unsqueeze(0)

        with torch.no_grad():

            out = model(batched)
            first_out = out[0]

            boxes = first_out['boxes'][first_out['scores'] > score_threshold]

            frame_tensor = torch.tensor(frame).permute(2, 0, 1)

            if boxes.size(0) > 0:
                frame_with_boxes = draw_bounding_boxes(
                    frame_tensor,
                    boxes,
                    width=8,
                    colors="blue"
                ).permute(1, 2, 0).numpy()
            else:
                frame_with_boxes = frame

        output_video.write(frame_with_boxes)

        # cv2.imshow('Bounding Boxes', frame_with_boxes)

        if cv2.waitKey(25) & 0xFF == ord('q'):
            break


    video.release()
    output_video.release()
    cv2.destroyAllWindows()



